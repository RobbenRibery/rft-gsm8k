# Rejection Sampling Fine-Tuning on GSM-8K
In this document, I provide a high-level summary of this project.
Please refers to Take_Home_Test.ipynb for detials about Hyperparameters, Training Logs, Evaluation Results, etc.
On top of what we asked for, I have put in some additioanl considersation, which I provide a high level overview in this document.

To start with, let's have a look at the
## Results on our take-home assignment:
Through rejection sampling on only 10% of the GSM-8K dataset, I've improved the model performance by [] on Maj@1.
The baseline Maj@1 is measured by using Phi-3.5-mini-insturct, resulting in 82.5% Maj@1 using temp=0.2 sampling at inference. 
My best model, fine-tuned using QLora (4-bit quntization with 16 rank), achieves [] Maj@1, using the same inference set up.

NOTE:
All evaluation performance is evaluated on 90% of the GSM-8K test dataset (1188) instances, since we've used the other 10% as evalaution set during fine-tuning. 
(In a more formal setting, we still have to evaluate on the remaining 10% of the test set)

## Further Considerations:
In [Yuan et,al](https://arxiv.org/pdf/2308.01825), each question $q_i$ is used to generate a reasoning paths $\{r_{i,j}\}_{j=1,...k}$ that is used to generate a prediction $a_{i,j}$. However, sampling $k$ reasoning paths for every single question is very computationally intense. The author also mentions that it's very time-consuming. 

Thus I wanted to see if I could achieve improvements by only using the most "useful" questions (i.e. only the top 10% most useful chunck) to perform rejection sampling, making RFT more data efficient.

### Question Selection Creteria 
Perhaps, one way to interpret the usefulness of a question is how many reasoning paths are required to solve it? 
If a question requiring 10 hops (hops = reasoning paths) to be solved at minimum, during the rejection sampling phase, the model would have higher chance to explore more diverse hops (i.e. take round trips, decribe 2 hops using one hop, etc) to solve the question, comparing to questions only requiring 1-3 hops to be solved.

In GSM8K, the nice thing is that each hop/reasoning path is written in a single line. We could use a simple hueristics to estimate the number of hops needed to solve a question:  

```python
utils.GSM8KParser.get_num_hops
@classmethod
    def get_num_hops(cls, answer_text: str) -> Dict[str, int]:
        """
        Calculate the number of steps in the solution.
        since GMS8k is highly structured.
        The higher the ouput, the more complex the problem

        Parameters
        ----------
        answer_text : str
            The answer text

        Returns
        -------
        int
            The number of steps in the solution
        """
        return {"num_hops": len(answer_text.strip().split("\n")) - 1} #take away one line to remve the #### final answer
```
In my experiment, I've used the top 747 questions (about 10% of the train set) in terms of number of estimated hops to perform rejection sampling at k=5. 

### Reasoning Path Selection Criteria
In [Yuan et,al](https://arxiv.org/pdf/2308.01825), the Levensthein Distance is used as the utility metric for the reasoning paths. 
Given all correct resoning paths generated by the model, the author select the most "novel" one by maximising its utility, which is the sum of all the pairwise Levenshtein Distance, apart from to itself. Think of it as summing each row inside a 2D matrix by ignoring the diagonal elelements.

But in the paper, the Levenshtein Distance is calculated on the reasoning paths ($r$), which is represented as a string in natural language(to be best of my knolwedge). I want to investigate if we could calculate the utility metric on parsed equations, including its surroding text as well, and still being able to select more diverse reasoning paths. Not to say that's necessarily a better way to do it, but an interersting variation worth exploring.

Please refers to ```utils.GMS8KParse.parse_equations_from_pred``` for more details, as well as a description of the regex pattern applied in such two cases. Overall, we find that using parsed equations without surrounding text is more effective in terms of selecting reasoning paths, which eventually encourges the model to generalise better. 

That said, the regex provided is not perfect. For example is in capaable of handling equaitons span across multiple lines. 

## Project Structure 

### datasets directory: 
This directory stores data 

### generations directory: 




## Engineering 

### 
